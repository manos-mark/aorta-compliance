{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import crop_and_pad\n",
    "from metrics import dice_loss, dice_coef, iou, hausdorff\n",
    "from train import read_image, read_mask\n",
    "from utils import create_dir, bland_altman_plot\n",
    "\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from natsort import natsorted\n",
    "from pydicom import dcmread\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyCompare\n",
    "import math\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_compliance_from_excel(patient_id, excel_path, asc_or_desc='asc'):\n",
    "    df = pd.read_excel(excel_path, index_col=0)\n",
    "    \n",
    "    try:\n",
    "        resolution, syst_press, diast_press, asc_min, asc_max, asc_compliance, \\\n",
    "            asc_distensibility, desc_min, desc_max, \\\n",
    "            desc_compliance, desc_distensibility = df.loc[patient_id, 'Resolution':]\n",
    "    except:\n",
    "        print('WARNING: Excel file is not correct')\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    if (not asc_min) or (not asc_max) or (not syst_press) or (not diast_press):\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    if asc_or_desc == 'asc':\n",
    "        compliance = compute_compliance(asc_min, asc_max, syst_press, diast_press)\n",
    "        return compliance, asc_min, asc_max, resolution, asc_distensibility\n",
    "    else:\n",
    "        compliance = compute_compliance(desc_min, desc_max, syst_press, diast_press)\n",
    "        return compliance, desc_min, desc_max, resolution, desc_distensibility\n",
    "    \n",
    "\n",
    "def fetch_compliance_from_excel(patient_id, excel_path, asc_or_desc='asc'):\n",
    "    df = pd.read_excel(excel_path, index_col=0)\n",
    "            \n",
    "    compliance = None\n",
    "    if asc_or_desc == 'asc':\n",
    "        compliance = df.loc[patient_id, 'asc-compliance']\n",
    "    else:\n",
    "        compliance = df.loc[patient_id, 'desc-compliance']\n",
    "        \n",
    "    return compliance\n",
    "\n",
    "\n",
    "def fetch_syst_press_from_excel(patient_id, excel_path):\n",
    "    df = pd.read_excel(excel_path, index_col=0)\n",
    "    return df.loc[patient_id, 'PS']\n",
    "\n",
    "\n",
    "def fetch_diast_press_from_excel(patient_id, excel_path):\n",
    "    df = pd.read_excel(excel_path, index_col=0)\n",
    "    return df.loc[patient_id, 'PD']\n",
    "\n",
    "        \n",
    "def compute_compliance(min_area, max_area, syst_press, diast_press):\n",
    "    return np.abs(max_area - min_area) / np.abs(syst_press - diast_press)\n",
    "\n",
    "def compute_distensibility(compliance, min_area):\n",
    "    return (compliance / min_area) * 1000\n",
    "\n",
    "\n",
    "def segment_aorta(model, image, display=False):\n",
    "    \"\"\" Predicting the mask \"\"\"\n",
    "    y_pred = model.predict(np.expand_dims(image, axis=0))[0] > 0.5\n",
    "    y_pred = y_pred.astype(np.float32)\n",
    "\n",
    "    if display:\n",
    "        \"\"\" Show the segmented aorta \"\"\"\n",
    "        plt.subplot(title='Predicted image & mask')\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.imshow(y_pred, cmap='jet', alpha=0.2)\n",
    "        plt.show()\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = 'unet-diana-lr_0.001-batch_8_augmented-healthy' # 'unet-diana-lr_0.001-batch_8-augmented'\n",
    "    \n",
    "\"\"\" File paths \"\"\"\n",
    "excel_path = os.path.join('..', 'dataset', 'Diana_Compliance_Dec2020.xlsx')\n",
    "DATASET_FOLDER_PATH = os.path.join('..', 'dataset', 'diana_segmented')\n",
    "# patient_ids = os.listdir(DATASET_FOLDER_PATH)\n",
    "\n",
    "# experiment_results_folder_path = os.path.join('..', 'results', EXPERIMENT)\n",
    "# create_dir(experiment_results_folder_path)\n",
    "\n",
    "\"\"\" Loading model \"\"\"\n",
    "with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss, 'hausdorff': hausdorff}):\n",
    "    model = tf.keras.models.load_model(os.path.join('..', \"output\", EXPERIMENT, \"model.h5\"), compile=False)    \n",
    "\n",
    "# results_df = pd.DataFrame()\n",
    "# predicted_compliances, original_compliances = ([] for i in range(2))\n",
    "# predicted_distensibilities, original_distensibilities = ([] for i in range(2))\n",
    "# original_min_areas, predicted_min_areas, original_max_areas, predicted_max_areas = ([] for i in range(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = '000000013461'\n",
    "patient_folder_path = os.path.join(DATASET_FOLDER_PATH, patient_id)  \n",
    "patient_output_folder_path = os.path.join('..', 'results', EXPERIMENT, patient_id)\n",
    "masks_output_folder_path = os.path.join('..', 'results', EXPERIMENT, patient_id, 'masks')\n",
    "# create_dir(patient_output_folder_path)\n",
    "# create_dir(masks_output_folder_path)\n",
    "\n",
    "\"\"\" Loading patient images \"\"\"\n",
    "image_paths = glob.glob(f'{patient_folder_path}/**/*.IMA', recursive=True)\n",
    "\n",
    "\"\"\" Loading patient predicted masks \"\"\"\n",
    "masks = glob.glob(f'{masks_output_folder_path}/**/*.png', recursive=True)\n",
    "\n",
    "\"\"\" Fetch pressure & areas from excel and compute compliance \"\"\"\n",
    "original_compliance, original_min, original_max, resolution, original_distensibility = compute_compliance_from_excel(patient_id, excel_path)\n",
    "# if (original_compliance is None) or (original_min is None) or (original_max is None):\n",
    "#     continue\n",
    "# original_compliances.append(original_compliance)\n",
    "# original_distensibilities.append(original_distensibility)\n",
    "\n",
    "\"\"\" Fetch systolic and distolic pressures from excel file \"\"\"\n",
    "syst_press = fetch_syst_press_from_excel(patient_id, excel_path)\n",
    "diast_press = fetch_diast_press_from_excel(patient_id, excel_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Segment the aorta and calculate area for each slice \"\"\"\n",
    "i = j = 0\n",
    "area_per_slice = []\n",
    "rows = int(math.ceil(len(image_paths)/5))\n",
    "fig, axs = plt.subplots(rows, 5, figsize=(30,30))\n",
    "\n",
    "for k, image_path in enumerate(tqdm(image_paths, total=len(image_paths))):  \n",
    "    mask_name = image_path.split('/')[3] + '_' + image_path.split('/')[5]\n",
    "    mask_name = mask_name + '_' + str(k) + '.png'\n",
    "    \n",
    "    image = read_image(image_path)\n",
    "    W,H = ((dcmread(image_path)).pixel_array).shape\n",
    "    \n",
    "    \"\"\" Segment aorta if it's not already segmented \"\"\"\n",
    "    if len(masks) == 0: # TODO make this len(masks) != len(image_paths)\n",
    "                        # now it will give error because we have multiple\n",
    "                        # scans for each patient\n",
    "        aorta = segment_aorta(model, image)\n",
    "        aorta = crop_and_pad(aorta[:,:,0], W, H)\n",
    "        img = np.zeros((aorta.shape[0], aorta.shape[1], 3))\n",
    "        img[:,:,0] = img[:,:,1] = img[:,:,2] = aorta[:,:]\n",
    "        # plt.imsave(os.path.join(masks_output_folder_path, mask_name), img, cmap='gray')\n",
    "    \n",
    "    else:\n",
    "        aorta = read_mask(os.path.join(masks_output_folder_path, mask_name))\n",
    "        aorta = crop_and_pad(aorta[:,:,0], W, H)\n",
    "        \n",
    "    image = crop_and_pad(image[:,:,0], W, H)\n",
    "    \n",
    "    # This is just for subploting all the masks in one image\n",
    "    axs[i,j].imshow(image, cmap='gray')\n",
    "    axs[i,j].imshow(aorta, cmap='jet', alpha=0.2)\n",
    "    axs[i,j].axis('off')\n",
    "    \n",
    "    if j < 4: j+=1\n",
    "    else: \n",
    "        j=0\n",
    "        if i < rows: i+=1\n",
    "    \n",
    "    \"\"\" Calculate area \"\"\"\n",
    "    area = cv2.countNonZero(aorta)\n",
    "    \n",
    "    \"\"\" Convert pixel to milimeters \"\"\"\n",
    "    area = int(area * resolution * resolution) # TODO is this correct? \n",
    "    area_per_slice.append(area)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Save areas and ROIs to files \"\"\"\n",
    "df = pd.DataFrame(area_per_slice)\n",
    "# df.to_excel(os.path.join(patient_output_folder_path, 'areas_per_slice.xlsx'), header=False)\n",
    "# fig.savefig(os.path.join(patient_output_folder_path, 'predicted_ROIs.jpg' ))\n",
    "#        plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\"\"\" Plot area over time \"\"\"\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.subplot(title='Area over time')\n",
    "plt.plot(area_per_slice)\n",
    "plt.xlabel('Slices')\n",
    "plt.ylabel('Area')\n",
    "plt.ylim(np.min(area_per_slice)-(np.min(area_per_slice)/2), np.max(area_per_slice)+(np.max(area_per_slice)/2))\n",
    "#        plt.show()\n",
    "# plt.savefig(os.path.join(patient_output_folder_path, 'predicted_area_over_time.jpg' ))\n",
    "plt.clf()\n",
    "\n",
    "\"\"\" Get the minimum and maximum areas across all slices \"\"\"        \n",
    "min_area = min(area_per_slice)\n",
    "max_area = max(area_per_slice)\n",
    "\n",
    "#        \"\"\" Get the median of 3 values close to minimum and maximum areas across all slices \"\"\"\n",
    "#        area_per_slice.sort()\n",
    "#        min_area = np.median(np.array(area_per_slice[:5]))\n",
    "#        max_area = np.median(np.array(area_per_slice[5:]))\n",
    "print('\\nPredicted areas STD: ', np.std(area_per_slice))\n",
    "print('Original min, max areas : ', original_min, original_max)\n",
    "print('Predicted min, max areas: ', min_area, max_area)\n",
    "\n",
    "original_min_areas.append(original_min)\n",
    "original_max_areas.append(original_max)\n",
    "predicted_min_areas.append(min_area)\n",
    "predicted_max_areas.append(max_area)\n",
    "\n",
    "\n",
    "\"\"\" Compute global ascending compliance \"\"\"\n",
    "predicted_compliance = compute_compliance(min_area, max_area, syst_press, diast_press)\n",
    "predicted_compliances.append(predicted_compliance)\n",
    "print('Original ascending compliance ', original_compliance)\n",
    "print('Predicted ascending compliance', predicted_compliance)\n",
    "\n",
    "\"\"\" Compute global ascending distensibility \"\"\"\n",
    "predicted_distensibility = compute_distensibility(predicted_compliance, min_area)\n",
    "predicted_distensibilities.append(predicted_distensibility)\n",
    "print('Original ascending distensibility ', original_distensibility)\n",
    "print('Predicted ascending distensibility', predicted_distensibility)\n",
    "    \n",
    "\"\"\" Save results to file \"\"\"\n",
    "df = pd.DataFrame([{\n",
    "        'patient_id': patient_id,\n",
    "        'min_area': original_min, \n",
    "        'max_area': original_max, \n",
    "        'syst_press': syst_press, \n",
    "        'diast_press': diast_press,\n",
    "        'min_area_pred': min_area, \n",
    "        'max_area_pred': max_area,\n",
    "        'compliance': original_compliance,\n",
    "        'compliance_pred': predicted_compliance,\n",
    "        'distensibility': original_distensibility,\n",
    "        'distensibility_pred': predicted_distensibility\n",
    "    }])\n",
    "try:\n",
    "    results_df = pd.concat([results_df, df], axis=0)\n",
    "    results_df.set_index('patient_id')\n",
    "except:\n",
    "    print('WARNING!!! Dublicate patient_id: ', patient_id)\n",
    "print('\\n ========================================================================== \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_excel(os.path.join(experiment_results_folder_path, 'results.xlsx'))\n",
    "    \n",
    "pyCompare.blandAltman(original_compliances, predicted_compliances, \n",
    "        # savePath=os.path.join(experiment_results_folder_path, 'ComplianceFigure.svg'), \n",
    "        figureFormat='svg')\n",
    "plt.clf()\n",
    "\n",
    "pyCompare.blandAltman(original_min_areas, predicted_min_areas, \n",
    "        # savePath=os.path.join(experiment_results_folder_path, 'MinAreasFigure.svg'), \n",
    "        figureFormat='svg')\n",
    "plt.clf()\n",
    "\n",
    "pyCompare.blandAltman(original_max_areas, predicted_max_areas, \n",
    "        # savePath=os.path.join(experiment_results_folder_path,'MaxAreasFigure.svg'), \n",
    "        figureFormat='svg')\n",
    "plt.clf()\n",
    "\n",
    "pyCompare.blandAltman(original_distensibilities, predicted_distensibilities, \n",
    "        # savePath=os.path.join(experiment_results_folder_path,'DistensibilityFigure.svg'), \n",
    "        figureFormat='svg')\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cd0f2bb9a875b5cfc4402d1e1ce521fec3e4fd525c7f70d840f6f2dac9333c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
